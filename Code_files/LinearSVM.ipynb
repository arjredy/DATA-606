{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearSVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDBcelh42P2j"
      },
      "source": [
        "<h1> Final model</h1>\n",
        "After performing analysis on several models, the best model which I decided as the best model was LinerSVM model. It has the capability to deal with huge data also yield good results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVO4tbSxiBhM",
        "outputId": "470c67c0-3090-4f5a-cc88-4383deaf6652"
      },
      "source": [
        "#Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TFn-gJFjKMR",
        "outputId": "24ed9114-58ba-4a9a-fafd-fe6977d5ab38"
      },
      "source": [
        "# Import NLTK libraries\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhIGRlR3jUsN"
      },
      "source": [
        "#Import Pandas\n",
        "import pandas as pd\n",
        "# Read the final_full_feature_reviews file\n",
        "data=pd.read_csv('final_full_feature_reviews.csv')\n",
        "data=data[['clean_text','review_stars']]\n",
        "\n",
        "# Cleaning the data by dropping Null value data\n",
        "data['clean_text'].dropna(inplace=True)\n",
        "# Use lowercace for the text in clean_text\n",
        "data['clean_text']=[i.lower() for i in data['clean_text']]\n",
        "# Use word_tokenize for data in clean text which is used to split large sample of text into words\n",
        "data['clean_text']=[word_tokenize(i) for i in data['clean_text']]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jB8WhOUjbhv"
      },
      "source": [
        "# Word Lemmatizer initially understands a word as Noun. To categorize a word with POS tag, word lemmatizer \n",
        "# needs to understand whether it is an adjective or verb or adverb.\n",
        "t_map = defaultdict(lambda : wn.NOUN)\n",
        "t_map['J'] = wn.ADJ\n",
        "t_map['V'] = wn.VERB\n",
        "t_map['R'] = wn.ADV"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUP4BxESjd17",
        "outputId": "a54f4d97-d5ba-407e-d837-9b8e36e3292d"
      },
      "source": [
        "for ind,ent in tqdm(enumerate(data['clean_text'])):\n",
        "    # Declare a list to store the words\n",
        "    word_list = []\n",
        "    # Initialize WordNetLemmatizer()\n",
        "    w_Lemmatized = WordNetLemmatizer()\n",
        "    # pos_tag function provides the 'tag' for the words whether it is a Noun(N) or Verb(V) or something.\n",
        "    for wrd, tag in pos_tag(ent):\n",
        "        # consider only alphabets and check for Stop words \n",
        "        if wrd not in stopwords.words('english') and wrd.isalpha():\n",
        "            w_Final = w_Lemmatized.lemmatize(wrd,t_map[tag[0]])\n",
        "            word_list.append(w_Final)\n",
        "       # After every iteration, list of processede words will be stored in 'text_final'\n",
        "    data.loc[ind,'text_final'] = str(word_list)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [44:59, 37.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bjo2igVn6ZL"
      },
      "source": [
        "data.to_csv('full_data_tfidf.csv', index=False)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG87T3bjjiS-"
      },
      "source": [
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(data['text_final'],data['review_stars'],test_size=0.3)\n",
        "\n",
        "# Encode the target variable to transform Categorical data of string type into numerical values\n",
        "Encoder = LabelEncoder()\n",
        "Train_Y = Encoder.fit_transform(Train_Y)\n",
        "Test_Y = Encoder.fit_transform(Test_Y)\n",
        "\n",
        "# Vectorize the words by using TF-IDF Vectorizer to find how important a word in document compared to corpus\n",
        "tfidf_v = TfidfVectorizer(max_features=5000)\n",
        "tfidf_v.fit(data['text_final'])\n",
        "\n",
        "Train_X_Tfidf = tfidf_v.transform(Train_X)\n",
        "Test_X_Tfidf = tfidf_v.transform(Test_X)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYiK-v7FjzWD",
        "outputId": "98d9817f-23a4-469c-a2ab-97672238b129"
      },
      "source": [
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "SVM.fit(Train_X_Tfidf,Train_Y)\n",
        "\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
        "\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score ->  65.16999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE52BE5Fj1xm",
        "outputId": "3bcd0d1d-ce3d-40e0-f58d-80fbdee44628"
      },
      "source": [
        "# Download the \".pkl\" file direct model execution\n",
        "from sklearn.externals import joblib\n",
        "joblib.dump(SVM, 'svm.pkl')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['svm.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "KxM48UKJnqxl",
        "outputId": "d274c179-248f-4cca-e977-f064ae31a8d6"
      },
      "source": [
        "# Cross tab for actual vs Predicted\n",
        "pd.crosstab(Test_Y,predictions_SVM)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3317</td>\n",
              "      <td>418</td>\n",
              "      <td>178</td>\n",
              "      <td>92</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>780</td>\n",
              "      <td>716</td>\n",
              "      <td>533</td>\n",
              "      <td>235</td>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>267</td>\n",
              "      <td>420</td>\n",
              "      <td>1137</td>\n",
              "      <td>1060</td>\n",
              "      <td>437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>117</td>\n",
              "      <td>112</td>\n",
              "      <td>617</td>\n",
              "      <td>3046</td>\n",
              "      <td>2926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>143</td>\n",
              "      <td>45</td>\n",
              "      <td>150</td>\n",
              "      <td>1602</td>\n",
              "      <td>11335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0     0    1     2     3      4\n",
              "row_0                              \n",
              "0      3317  418   178    92    191\n",
              "1       780  716   533   235    126\n",
              "2       267  420  1137  1060    437\n",
              "3       117  112   617  3046   2926\n",
              "4       143   45   150  1602  11335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAHBzIwy24SS",
        "outputId": "08c1c198-a1d2-4b09-eeff-ceeb0077d0ce"
      },
      "source": [
        "Train_X.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2ymLKPq96VJ",
        "outputId": "25de2aef-72f3-4a40-91cf-930dc28fe296"
      },
      "source": [
        "Train_X_Tfidf.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "372z5AQP-Baa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}